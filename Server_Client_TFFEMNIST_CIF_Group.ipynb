{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Server_Client_TFFEMNIST_CIF_Group\n",
    "\n",
    "Purpose: This is the group code intended to be updated by all\n",
    "\n",
    "Contains: TFF-EMNIST database, CIF (Data Quality + SINR) function\n",
    "\n",
    "Date of Creation: November 25th, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all Packages ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgior\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20201111). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "import nest_asyncio\n",
    "%reload_ext tensorboard\n",
    "nest_asyncio.apply()\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in TFF - EMNIST Data Set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Server Class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class server:\n",
    "    \n",
    "    def __init__(self, numOfClients):\n",
    "        self.numOfClients = numOfClients #Num of Client\n",
    "        self.clientIds = list(range(0,self.numOfClients)) #Client List\n",
    "        self.updateRoundNum = 0  # Update Round Number\n",
    "        self.serverModel = self.createBaseModel() #Create a Keras Model for MNIST\n",
    "        self.clientActive = [] #If client is available or not based on time - day/night\n",
    "        self.clientCIF = []\n",
    "        self.clientSelected = []\n",
    "        self.maxClientsPerRound = 5\n",
    "        self.updateFromClients=[]\n",
    "        self.__serverTestData_X=[]\n",
    "        self.__serverTestData_Y=[]\n",
    "        self.__serverTestData = self.setServerTestDataTFF(emnist_test)\n",
    "        self.predictionAcc=[]\n",
    "        self.predictionLoss=[]\n",
    "        \n",
    "        \n",
    "    def createBaseModel(self):\n",
    "        #return tf.keras.models.Sequential([\n",
    "        #    Dense(64, activation='relu',input_shape=(784,)),\n",
    "        #    Dense(64, activation='relu'),\n",
    "        #    Dense(10, activation='softmax'),])\n",
    "        return tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(784,)),\n",
    "            tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "            tf.keras.layers.Softmax()])\n",
    "    \n",
    "    def setServerTestData(self,Xtest,Ytest):  # NOT USED IN THIS CASE\n",
    "        self.__serverTestData_X=Xtest\n",
    "        self.__serverTestData_Y=Ytest\n",
    "        \n",
    "    def setServerTestDataTFF(self,serverTestData):  #Creates a test set for server\n",
    "        BATCH_SIZE = 100\n",
    "        SHUFFLE_BUFFER = 100\n",
    "        PREFETCH_BUFFER= 10\n",
    "\n",
    "        def preprocess(dataset):\n",
    "            def batch_format_fn(element):\n",
    "                \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "                return collections.OrderedDict(\n",
    "                    x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "                    y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "            return dataset.repeat(10).shuffle(SHUFFLE_BUFFER).batch(\n",
    "              BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "        serverData = tfds.as_numpy(preprocess(serverTestData.create_tf_dataset_for_client(serverTestData.client_ids[30])))\n",
    "\n",
    "        return serverData\n",
    "     \n",
    "        \n",
    "    def initialBroadcast(self):\n",
    "        for i in self.clientIds:\n",
    "            clientName = client_list[\"client_\"+str(self.clientIds[i])]  #Create Client Name, Using Client_List Dictionary\n",
    "            #clientName = \"client_\"+str(self.clientIds[i])  #Create Client Name\n",
    "            #print(clientName)\n",
    "            clientName.setInitialModel(self.serverModel) #setInitialModel-> Method of client Class\n",
    "            #eval(clientName).setInitialModel(self.serverModel) #setInitialModel-> Method of client Class\n",
    "            \n",
    "    def getClientActiveStatus(self):  #if the client is available for update or not randomly set in client\n",
    "        self.clientActive = []\n",
    "        for i in self.clientIds:\n",
    "            clientName = client_list[\"client_\"+str(self.clientIds[i])]  #Create Client Name\n",
    "            #print(clientName)\n",
    "            if(clientName.sendActiveStatus() == 1): #getActiveStatus() -> method of client class\n",
    "                self.clientActive.append(i)\n",
    "               \n",
    "    def getClientCIF(self): # Get Client Importance Factor for active clients\n",
    "        self.clientCIF=[]\n",
    "        for i in self.clientActive:\n",
    "            clientName = client_list[\"client_\"+str(i)]\n",
    "            c_cif = clientName.sendCIF()   #sendCIF() - method of client\n",
    "            self.clientCIF.append(c_cif)\n",
    "        print(\"Clients with Acceptable CIF: \", self.clientCIF)\n",
    "        \n",
    "    def getClientSelected(self): # Select The Top (N = maxClientsPerRound) with the highest CIF value\n",
    "        self.clientSelected = []\n",
    "        # Use non-class, local variables to leave class variables clean\n",
    "        clientCIF, clientActive = ( list(t) for t in zip(*sorted(zip(self.clientCIF, self.clientActive)))) # Sort Active Clients and their CIF values, by CIF\n",
    "        self.clientSelected  = clientActive[-self.maxClientsPerRound:] # Select the N=maxClientsPerRound of clients with highest CIF\n",
    "        self.clientCIF = clientCIF[-self.maxClientsPerRound:] # Select the N=maxClientsPerRound of highest CIF\n",
    "            \n",
    "    \n",
    "    def getModelUpdateFromClients(self):\n",
    "        print(\"--------------------------------------------\\n\",\"Round NO:\",self.updateRoundNum)\n",
    "        print(\"Active Clients: \",self.clientActive)\n",
    "        print(\"CIF of Active Clients: \", self.clientCIF)\n",
    "        print(\"Selected Clients: \", self.clientSelected)\n",
    "        print(\"Training Clients with CIF > 10\")\n",
    "        self.updateRoundNum +=1\n",
    "        self.updateFromClients=[]\n",
    "        #self.dataPointsClients=[]\n",
    "        \n",
    "        for i in range (0,len(self.clientSelected)):\n",
    "            if self.clientCIF[i] >= 10:  #Select Client only if CIF > some value 10 chosen for testing ONLY\n",
    "                clientName = client_list[\"client_\"+str(int(self.clientSelected[i]))]\n",
    "                self.updateFromClients.append(clientName.sendClientUpdate()) #Get a list of updates from selected clients\n",
    "            \n",
    "        avgModelWeights = self.computeFedAvg(self.updateFromClients)\n",
    "        #print(\"average model weights = \\n\",avgModelWeights)\n",
    "        self.serverModel.set_weights(avgModelWeights)   \n",
    "        \n",
    "    def computeFedAvg(self,updates):  #Compute Federated Averaging from Available Clients\n",
    "        totalDataPoints = 0\n",
    "        scaleFactor=[]\n",
    "        for i in range (0,len(updates)):\n",
    "            totalDataPoints += updates[i][1]   #Sum the total Data Points on All Available Clients\n",
    "            scaleFactor.append(updates[i][1])  #Store individual number datapoints for clients\n",
    "\n",
    "        scaleFactor = np.array(scaleFactor)/totalDataPoints #Create the scale factor\n",
    "       \n",
    "        sumOfAvgWeights = []*len(updates[0][0]) \n",
    "        \n",
    "        for j in range (0,len(updates[0][0])): #range of layers\n",
    "            k=np.zeros_like(updates[0][0][j])\n",
    "            #print(\"ShapeofK:\",k.shape)\n",
    "            for i in range(0,len(updates)): #range of clients\n",
    "                k=k+updates[i][0][j]*scaleFactor[i]\n",
    "                #print(\"ShapeofK:\",k.shape)\n",
    "            sumOfAvgWeights.append(k)\n",
    "      \n",
    "        return sumOfAvgWeights   \n",
    "    \n",
    "    def testServerModel(self):\n",
    "        self.serverModel.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                                optimizer = tf.keras.optimizers.SGD (learning_rate=.01),\n",
    "                                metrics=['accuracy'])\n",
    "        testData = next(iter(self.__serverTestData))\n",
    "        return self.serverModel.evaluate(testData['x'],\n",
    "                                         testData['y'])\n",
    "        \n",
    "        \n",
    "    def updateAllClients(self):\n",
    "        for i in self.clientIds:\n",
    "            clientName = client_list[\"client_\"+str(self.clientIds[i])]  #Create Client Name\n",
    "            clientName.setModelUpdateWeights(self.serverModel.get_weights()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Client Class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class client:\n",
    "    \n",
    "    def __init__(self,ID):\n",
    "        self.id = ID\n",
    "        self.__clientModel = tf.keras.models.Sequential()\n",
    "        self.__clientModelWeights=[]\n",
    "        self.activeStatus = 0\n",
    "        self.__clientDataX=[] #Private to Client\n",
    "        self.__clientDataY=[]\n",
    "        self.clientCIF=0\n",
    "        self.meanSINR = int(np.random.normal(15, 2.5, 1)) #Select random int from normal dist \n",
    "        self.roundSINR = 0\n",
    "        self.propFair = 0\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.01\n",
    "        self.__clientData = self.__clientDataFromTFF(emnist_train)\n",
    "        \n",
    "    def __clientDataFromTFF(self,tffDataset):\n",
    "        NUM_EPOCHS = self.epochs\n",
    "        BATCH_SIZE = 100\n",
    "        SHUFFLE_BUFFER = 100\n",
    "        PREFETCH_BUFFER= 10\n",
    "\n",
    "        def preprocess(dataset):\n",
    "            def batch_format_fn(element):\n",
    "                \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "                return collections.OrderedDict(\n",
    "                    x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "                    y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "            return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "              BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "        \n",
    "        return tfds.as_numpy(preprocess(tffDataset.create_tf_dataset_for_client(tffDataset.client_ids[self.id])))\n",
    "    \n",
    "    \n",
    "    #Methods Private to client\n",
    "    def __setActiveStatus(self): \n",
    "        #self.activeStatus = int(np.random.randint(0,2,1))\n",
    "        self.activeStatus = 1\n",
    "    \n",
    "    def __setRoundSINR(self):\n",
    "        self.roundSINR = np.round((np.random.normal(self.meanSINR, 1, 1)[0]), 2)\n",
    "                               \n",
    "    def __setPropFair(self):\n",
    "        self.propFair = self.roundSINR / self.meanSINR\n",
    "        \n",
    "    def __setdataQuality(self):\\\n",
    "        \n",
    "        ## Calculate for entropy - Start ##\n",
    "        \n",
    "#         for values in classification_probabilities:\n",
    "#           for value in values:\n",
    "#             score += value * np.log(value)\n",
    "#         score = score * -1\n",
    "\n",
    "        ## Calculate for entropy - End ##\n",
    "        \n",
    "        self.dataQuality = 20 # Set 20 so that CIF value will always be passing\n",
    "    \n",
    "    def __setCIF(self):\n",
    "        #self.clientCIF = int(np.random.randint(0,50,1))  # Random Number between 0 and 49 for check purpose only\n",
    "        self.__setRoundSINR()\n",
    "        self.__setPropFair() #This is currently unused\n",
    "        self.__setdataQuality()\n",
    "        self.clientCIF = self.roundSINR + self.dataQuality\n",
    "        # self.clientCIF = (-1/self.roundSINR) + self.dataQuality #Formula for computing client CIF\n",
    "        \n",
    "    def __getTrainData(self):\n",
    "        return self.__clientDataX, self.__clientDataY  # Just for Testing will be expanded to select meaningful data\n",
    "    \n",
    "    #Public Methods\n",
    "    def sendActiveStatus(self):\n",
    "        self.__setActiveStatus()\n",
    "        return self.activeStatus\n",
    "    \n",
    "    def sendCIF(self):\n",
    "        self.__setCIF()\n",
    "        return self.clientCIF\n",
    "    \n",
    "    def setInitialModel(self,model):\n",
    "        self.__clientModel=model\n",
    "        print(self.__clientModel.summary)\n",
    "         \n",
    "    def setClientData(self,X,Y):\n",
    "        self.__clientDataX = X\n",
    "        self.__clientDataY = Y\n",
    "   \n",
    "\n",
    "    def sendClientUpdate(self):\n",
    "        print(\"->\",self.id,end=\" \")\n",
    "        self.__clientModel.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                                optimizer = tf.keras.optimizers.SGD (learning_rate=self.lr),\n",
    "                                metrics=['accuracy'])\n",
    "        #print(self.__clientDataX.shape)\n",
    "        #print(self.__clientDataY.shape)\n",
    "        if len(self.__clientDataX) > 0:\n",
    "            history = self.__clientModel.fit(self.__clientDataX,\n",
    "                                   tf.keras.utils.to_categorical(self.__clientDataY),\n",
    "                                   epochs=self.epochs,\n",
    "                                   validation_split=0.2,\n",
    "                                   verbose=0,\n",
    "                                    shuffle=True)\n",
    "\n",
    "            updatedWeights = self.__clientModel.get_weights()\n",
    "        \n",
    "        else:\n",
    "            currentData = next(iter(self.__clientData))\n",
    "            history = self.__clientModel.fit(currentData['x'],\n",
    "                                   currentData['y'],\n",
    "                                   epochs=self.epochs,\n",
    "                                   verbose=0,shuffle=True)\n",
    "\n",
    "            updatedWeights = self.__clientModel.get_weights()\n",
    "       \n",
    "        \n",
    "        numOfDataPoints = len(currentData['x'])   #<-- Set the correct type to get the number of datapoints in the current update round\n",
    "\n",
    "        return (updatedWeights,numOfDataPoints)\n",
    "    \n",
    "    def setModelUpdateWeights(self,modelUpdateWeights):\n",
    "        self.__clientModel.set_weights(modelUpdateWeights)\n",
    "        #self.__clientModel.\n",
    "        \n",
    "    def plotClientData(self):\n",
    "        #print(\"Y_Data\",self.__clientDataY)\n",
    "        id0=[]\n",
    "        id1=[]\n",
    "        id2=[]\n",
    "        id3=[]\n",
    "        id4=[]\n",
    "        id5=[]\n",
    "        id6=[]\n",
    "        id7=[]\n",
    "        id8=[]\n",
    "        id9=[]\n",
    "        for i in range (0,len(self.__clientData['x'])):\n",
    "            for j in range (0,10):\n",
    "                if j==self.__clientData['y']:\n",
    "                    eval('id'+str(j)).append(i)\n",
    "        xAxis=['0','1','2','3','4','5','6','7','8','9']\n",
    "        yAxis=[len(id0),len(id1),len(id2),len(id3),len(id4),len(id5),len(id6),len(id7),len(id8),len(id9)]\n",
    "        plt.bar(xAxis,yAxis)\n",
    "        title=\"Data for Client\"+str(self.id)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Clients ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_list = {}\n",
    "\n",
    "# Set the number of clients\n",
    "num_clients = 10\n",
    "for i in range(num_clients):\n",
    "    name = \"client_\" + str(i)\n",
    "    client_list[name] = client(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Server ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize server with number of clients\n",
    "serverFA = server(num_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Broadcast from Server to Client ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverFA.initialBroadcast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTraingRounds = 15\n",
    "trainingMetrics=[]*numberOfTraingRounds\n",
    "for i in range(0,numberOfTraingRounds):\n",
    "    serverFA.getClientActiveStatus()\n",
    "    serverFA.getClientCIF()\n",
    "    serverFA.getClientSelected()\n",
    "    serverFA.getModelUpdateFromClients()\n",
    "    trainingMetrics.append(serverFA.testServerModel())\n",
    "    serverFA.updateAllClients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainingMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop right there!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
